{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5897405",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jcausey-astate/ASRI-2025/blob/main/python_intermediate_regression_ASRI25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd587a",
   "metadata": {},
   "source": [
    "# Regression Techniques in Python (Intermediate)\n",
    "## ASRI 2025\n",
    "\n",
    "\n",
    "![Regression in Python (Intermediate)](https://jcausey-astate.github.io/ASRI-2025/images/regression_in_python_title_card.svg)\n",
    "\n",
    "The notebook uses the following modules:\n",
    "\n",
    "* `matplotlib`  : Provides basic graphing/charting.\n",
    "* `numpy`       : Allows matrix and vector/array math.\n",
    "* `pandas`      : Provides DataFrame functionality.\n",
    "* `seaborn`     : Works with `matplotlib` to provide nicer graphs.\n",
    "* `sklearn`     : Scikit-Learn provides machine learning and data manipulation tools.\n",
    "\n",
    "We will rely heavily on the Scikit-Learn library for models, metrics, and\n",
    "experimental design tools.  See the full documentation for this fantastic\n",
    "library at <https://scikit-learn.org>.\n",
    "\n",
    "---\n",
    "\n",
    "## First, some terms and definitions:\n",
    "\n",
    "**_Regression_** is the process of predicting a _continuous value_ given\n",
    "the _random variables_ for a given _sample_.\n",
    "\n",
    "**_Continuous_** values are numeric values that can take on any value within\n",
    "some range. Examples include height, weight, temperature, price, etc.\n",
    "\n",
    "A **_sample_** consists of all of the experimental information gathered for one\n",
    "item in the dataset.  Sometimes a _sample_ is called an _object_ or _item_.\n",
    "Usually samples are arranged as _rows_ in tabular datasets (CSV files, Excel\n",
    "spreadsheets, or similar).\n",
    "\n",
    "A **_random variable_**, sometimes called an _input variable_, _measurement_, or\n",
    "_feature_, is the recorded value for some property of the sample that was\n",
    "measured in the experiment, e.g. \"weight\", \"horsepower\", \"number of cylinders\", etc.\n",
    "\n",
    "#### You have a _regression_ problem if the dependent variable (output value) you are trying to predict is _continuous_.\n",
    "\n",
    "We will focus first on regression problems where the random variables are\n",
    "also _continuous_.\n",
    "\n",
    "At the end, a section is provided with some tips for working with random variables that\n",
    "are _categorical_.\n",
    "\n",
    "___\n",
    "\n",
    "## Let's see some code!\n",
    "\n",
    "First, we have to import the modules, objects, and functions we will be using\n",
    "in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a555d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8075f0e8",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "\n",
    "For this tutorial, we will use the \"Auto MPG\" dataset, which is a classic dataset for regression tasks. \n",
    "It contains information about various automobiles, including their fuel consumption in miles per gallon (mpg, \n",
    "which will be our target variable to predict.\n",
    "\n",
    "Let's load the dataset and take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names based on the dataset description\n",
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', \n",
    "                'acceleration', 'model_year', 'origin', 'car_name']\n",
    "\n",
    "# Download the dataset from UCI ML Repository if needed.\n",
    "! [[ -f auto+mpg.zip ]] || { wget https://archive.ics.uci.edu/static/public/9/auto+mpg.zip && unzip -o auto+mpg.zip && rm Index auto-mpg.data-original; }\n",
    "\n",
    "# Load the dataset\n",
    "auto_mpg = pd.read_csv('auto-mpg.data', sep=r'\\s+', names=column_names)\n",
    "\n",
    "# Display the first few rows\n",
    "auto_mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f638564",
   "metadata": {},
   "source": [
    "The **mpg** column contains the value that we want to predict (it is our\n",
    "_target_ column).  We'll use the other numeric columns as random\n",
    "variables (predictors).\n",
    "\n",
    "It will make things easier if we create variables to contain the name of the\n",
    "target column and the random variables.  These can be used when we interact with\n",
    "Pandas DataFrames to quickly select those columns by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f4c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"mpg\"\n",
    "random_var_cols = [\n",
    "    \"cylinders\",\n",
    "    \"displacement\",\n",
    "    \"horsepower\",\n",
    "    \"weight\",\n",
    "    \"acceleration\",\n",
    "    \"model_year\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da4fd90",
   "metadata": {},
   "source": [
    "Let's use the `info()` DataFrame method to see what kinds of values we have, and whether there are any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42174a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the `info()` method on `auto_mpg` to see value counts \n",
    "# and types:\n",
    "# TODO: Place code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51981f0",
   "metadata": {},
   "source": [
    "ü§î  We notice that the 'horsepower' column is not recognized as numeric (the type is reported as \"`object`\"). Let's check if there are any non-numeric values.  \n",
    "\n",
    "One way to do that is to look at the values.   Another is to write a function to check if each value can be converted to a `float`, and return True if it can or False otherwise.  Then, we can just filter for values that will not convert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ec075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(x):\n",
    "    \"\"\"Returns True if `x` is a number, or False otherwise.\"\"\"\n",
    "    try:\n",
    "        float(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "# List the values and counts for all non-numeric values in the 'horsepower' variable:\n",
    "auto_mpg.loc[auto_mpg['horsepower'].apply(is_number) == False, 'horsepower'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d821ac",
   "metadata": {},
   "source": [
    "From this, we can see that the only non-numeric value is '?'.  So, we could convert the column to numeric after replacing the '?' values with `na.nan`, or we can just reload the DataFrame from the CSV file and tell Pandas to treat '?' as NA.  We will do the latter to demonstrate how to do it, and because this dataset is small enough that it will not take long to do it that way.  (For larger data, the former approach would probably be faster.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the dataset, treating '?' as NA values.\n",
    "auto_mpg = pd.read_csv('auto-mpg.data', sep=r'\\s+', names=column_names, na_values='?')\n",
    "# Check the info again\n",
    "auto_mpg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b228a",
   "metadata": {},
   "source": [
    "Now, we have correct data types.  We will still have missing values in 'horsepower' though, so we need to remove those rows:\n",
    "\n",
    "‚ÑπÔ∏è Pandas has a method called `dropna()` that can drop missing values.\n",
    "\n",
    "In this case, we want to call it with the `subset` argument set to our random variable cols (`random_var_cols`) and the `axis` argument set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now drop rows with missing values\n",
    "# TODO: complete the statement below, adding to the `auto_mpg`\n",
    "# on the right-hand side.\n",
    "auto_mpg = auto_mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f4cddf",
   "metadata": {},
   "source": [
    "### üìä Visualize Early, Visualize Often\n",
    "\n",
    "Let's take a look at the dataset.  We will plot some relationships between our target variable (mpg) and the predictors.   _(This will take several seconds.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba184ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(auto_mpg[random_var_cols + [target_col]], corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498de43",
   "metadata": {},
   "source": [
    "Looking at the pairplot, we can see that there are clear relationships between MPG and the various predictors (bottom row).\n",
    "For example, as weight increases, MPG tends to decrease. Similarly, as horsepower and displacement increase, \n",
    "MPG tends to decrease. These relationships make intuitive sense: heavier cars with more powerful engines \n",
    "typically consume more fuel.  \n",
    "\n",
    "We can also see that some of the predictors have relationships with one another, which could be a problem for \n",
    "models that assume independent variables.  Let's get a sense of that by plotting the (Spearman) _correlation_ \n",
    "between all the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe064803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix.  We use Spearman because we observed some non-linear relationships in the pairplot.\n",
    "correlation_matrix = auto_mpg[random_var_cols + [target_col]].corr('spearman')\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6433a2a",
   "metadata": {},
   "source": [
    "The correlation matrix confirms our observations from the scatter plots. We can see strong negative correlations \n",
    "between MPG and weight, displacement, and horsepower. This suggests that these variables will be important \n",
    "predictors in our regression models.\n",
    "\n",
    "‚ú® Choosing the right random variables for prediction is **vital**.  This is why\n",
    "it is a good idea to get to know your dataset early in the process!  **Visualize\n",
    "early, visualize often!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700b875",
   "metadata": {},
   "source": [
    "## Let's see how well we can predict MPG with a linear model.\n",
    "\n",
    "First, we'll use the `LinearRegression` model from scikit-learn.\n",
    "\n",
    "Based on the visualizations above, let's start with a simple model using just weight and displacement as predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f916a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill the list `simple_random_var_cols` with the names of the columns\n",
    "# we want to use: \"weight\" and \"displacement\"\n",
    "simple_random_var_cols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1388b7cd",
   "metadata": {},
   "source": [
    "For scoring, we will use _R¬≤_ and Mean Absolute Error (MAE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = {\n",
    "    'r2': 'r2',\n",
    "    'mae': 'neg_mean_absolute_error',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ffc30",
   "metadata": {},
   "source": [
    "To quickly determine if a linear model will be suitable for this problem, we can use the\n",
    "`cross_validate()` function from Scikit-Learn.  This function wraps up a\n",
    "**lot** of functionality.  It will set up a [_k-fold cross validation_ experiment](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "(with default of $k=5$, for five-fold CV).  It will take the model of your\n",
    "choice and automatically _train_ the model for each training fold, then\n",
    "_predict_ the test cases and _score_ the predictions on the test folds (with the\n",
    "_R¬≤_ metric by default for regression).\n",
    "\n",
    "The scores for each fold are returned.  We can calculate and report the mean\n",
    "score over all five folds along with the standard deviation of the scores to see\n",
    "whether the model is able to do a good job in general, and how much variation we\n",
    "would expect for different training sets.  Models should have high R¬≤ values, and\n",
    "a low standard deviation would indicate that the model generalizes to new data\n",
    "very well.  (A high standard deviation would indicate the model is unstable and\n",
    "doesn't generalize well.)  For the Mean Absolute Error metric, we want _smaller_ \n",
    "values (less deviation from the true mpg, and a small standard deviation.\n",
    "\n",
    "The linear model will look like:\n",
    "\n",
    "$$\n",
    "y_{mpg} = \\beta_0 + \\beta_1 x_{weight} + \\beta_2 x_{displacement}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b38020",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    LinearRegression(), X=auto_mpg[simple_random_var_cols], y=auto_mpg[target_col],\n",
    "    scoring=scoring_metrics\n",
    ")\n",
    "print(\n",
    "    f\"mean R¬≤ : {scores['test_r2'].mean():0.3f}, std: {scores['test_r2'].std():0.3f}\\n\"\n",
    "    f\"mean MAE: {-scores['test_mae'].mean():0.1f} mpg, std: {scores['test_mae'].std():0.1f} mpg.\"\n",
    ")  # print mean and standard deviation of score metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910eb1bf",
   "metadata": {},
   "source": [
    "üòû The two-variable linear model seems pretty unstable at this task.  Look closely at the R¬≤ mean: 0.326 is a pretty low R¬≤ value to begin with, and the standard deviation over the 5 runs of the cross-validation experiment was 0.523, which is larger than the mean value!  That means that on average, the linear model can explain only about 33% of the variance in the data, and the high standard deviation means that the model is not generalizing very well.\n",
    "\n",
    "ü§î We might have expected this if we look back at our pair plots of weight and displacement versus mpg.  Do you see the \"curve\" to the scatter?  That is a good indicator that a linear model might not be ideal for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc54fcf",
   "metadata": {},
   "source": [
    "**Let's scale the model up to use all of our predictors.**\n",
    "\n",
    "For now, we will stick with a linear model.  But, let's use all of our random variables to see if that improves the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb10498",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    LinearRegression(), X=auto_mpg[random_var_cols], y=auto_mpg[target_col],\n",
    "    scoring=scoring_metrics\n",
    ")\n",
    "print(\n",
    "    f\"mean R¬≤ : {scores['test_r2'].mean():0.3f}, std: {scores['test_r2'].std():0.3f}\\n\"\n",
    "    f\"mean MAE: {-scores['test_mae'].mean():0.1f} mpg, std: {scores['test_mae'].std():0.1f} mpg.\"\n",
    ")  # print mean and standard deviation of score metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91018641",
   "metadata": {},
   "source": [
    "This provided a modest improvement, both in R¬≤ and standard deviation.  We see a smaller change in MAE and its standard deviation, but still an improvement nonetheless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760a6de",
   "metadata": {},
   "source": [
    "**Let's try a non-linear model.**  Let's consider a quadratic model (a polynomial model of degree 2).  The model will look like:\n",
    "\n",
    "$$\n",
    "y_{mpg} = \\beta_0 + \\beta_1 x_{weight} + \\beta_2 x_{displacement} + \\beta_3 x_{weight}^2 + \\beta_4 x_{displacement}^2\n",
    "$$\n",
    "\n",
    "The way we do this is to pre-compute the polynomial features $x_{weight}^2$ and $x_{displacement}^2$, then use a linear regression model as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "scores = cross_validate(\n",
    "    LinearRegression(), X=poly.fit_transform(auto_mpg[random_var_cols]), y=auto_mpg[target_col],\n",
    "    scoring=scoring_metrics\n",
    ")\n",
    "print(\n",
    "    f\"mean R¬≤ : {scores['test_r2'].mean():0.3f}, std: {scores['test_r2'].std():0.3f}\\n\"\n",
    "    f\"mean MAE: {-scores['test_mae'].mean():0.1f} mpg, std: {scores['test_mae'].std():0.1f} mpg.\"\n",
    ")  # print mean and standard deviation of score metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0816c77",
   "metadata": {},
   "source": [
    "üéâ Now we see a better result.  R¬≤ above 65% is starting to look more promising (but not necessarily \"good\").  We see that on average our model is off by about 2.6 mpg.  If that is an acceptable error amount, we might be happy with this one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95f39b",
   "metadata": {},
   "source": [
    "Now, let's take a look at a different kind of model, just for comparison.  A _Random\n",
    "Forest_ model is a non-linear model that works well for lots of tasks.\n",
    "Scikit-Learn provides one called [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) for regression problems.\n",
    "\n",
    "Let's try it in exactly the same experimental setup we used for the linear\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    RandomForestRegressor(random_state=1),\n",
    "    X=auto_mpg[random_var_cols],\n",
    "    y=auto_mpg[target_col],\n",
    "    scoring=scoring_metrics\n",
    ")\n",
    "print(\n",
    "    f\"mean R¬≤ : {scores['test_r2'].mean():0.3f}, std: {scores['test_r2'].std():0.3f}\\n\"\n",
    "    f\"mean MAE: {-scores['test_mae'].mean():0.1f} mpg, std: {scores['test_mae'].std():0.1f} mpg.\"\n",
    ")  # print mean and standard deviation of score metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c062b",
   "metadata": {},
   "source": [
    "The random forest did even better than the quadratic model! This suggests that there might be non-linear relationships in the data that the random forest is able to capture better than either the linear or quadratic models.\n",
    "\n",
    "**One note:**\n",
    "\n",
    "We used `random_state=1` to _seed_ the random number generator within the model,\n",
    "causing it to produce identical results if we train it again on the same data.\n",
    "Random forests (as implied by their name) rely on some randomness during\n",
    "training, so you don't expect to get the same performance every time.  This\n",
    "makes **reproducible results** difficult.\n",
    "\n",
    "üí° By seeding the random state, we \"lock\" it to a specific outcome (assuming no\n",
    "external changes).  This way, others can reproduce our results in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4f4bb",
   "metadata": {},
   "source": [
    "## Exploring more ways to characterize regressor performance.\n",
    "\n",
    "### üìä Visualize!\n",
    "\n",
    "When evaluating regression models, it's important to look at the residuals (the differences between predicted and actual values). \n",
    "A good regression model should have residuals that are randomly distributed around zero.\n",
    "\n",
    "Let's split our data into training and testing sets, train our models, and then visualize the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e08467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    auto_mpg[random_var_cols], auto_mpg[target_col], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train the linear regression model\n",
    "# TODO: Create a `LinearRegression` model with no parameters and use \n",
    "# its `fit` method to fit `X_train` to `y_train`\n",
    "linear_model = None # TODO: CODE HERE REPLACES `None`\n",
    "\n",
    "# Make predictions on the test set\n",
    "linear_preds = linear_model.predict(X_test)\n",
    "\n",
    "# Calculate residuals\n",
    "linear_residuals = y_test - linear_preds\n",
    "\n",
    "# Plot the residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(linear_preds, linear_residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('Predicted MPG')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot for Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a83be7",
   "metadata": {},
   "source": [
    "‚ú® **Interpreting a residual plot:**  To interpret a residual plot like the one above, we look at two things: (1) The magnitude of the residuals, which represents how far our predictions are from the actual values.  We want the dots to be close to the zero line.  (2) The **_shape_** of the residuals.  The plotted residuals are ordered by magnitude of the prediction from smallest to largest, covering the range of predicted values.  What we _want_ is to see no trend or \"pattern\" to the scatter of residuals versus the zero line.  If we see a trend or pattern, then it is a clue that our model is not making the same mistakes across the range of its outputs, and so it might not be a good fit for the application.\n",
    "\n",
    "Here, we see that there is a \"curve\" in the residuals&mdash;they start above the zero line, trend downward, then back up again (a \"smile\" pattern).  This is a clue that the actual target variable \"mpg\" is probably not a linear function of the predictors.  A non-linear model might work better.\n",
    "\n",
    "\n",
    "Now let's do the same plot for the Random Forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the random forest model\n",
    "rf_model = RandomForestRegressor(random_state=1).fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate residuals\n",
    "rf_residuals = y_test - rf_preds\n",
    "\n",
    "# Plot the residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(rf_preds, rf_residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('Predicted MPG')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot for Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83a4b2",
   "metadata": {},
   "source": [
    "**Here, we don't see as much of a pattern.** That is a _good thing_.  For the most part, our Random Forest model seems to be making similar errors across its range, with two possible exceptions: The smaller predictions seem to be better than the larger ones in general, and there is a rough patch between about 22 and 32 mpg. where the model seems to be over-predicting more than everywhere else.  An even more powerful model might be able to do a better job, but we won't investigate that in this workshop.\n",
    "\n",
    "üí° **Another way to visualize the errors:** Let's also compare the _actual vs. predicted_ values for both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot actual vs predicted for Linear Regression\n",
    "ax1.scatter(y_test, linear_preds)\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax1.set_xlabel('Actual MPG')\n",
    "ax1.set_ylabel('Predicted MPG')\n",
    "ax1.set_title('Linear Regression: Actual vs Predicted')\n",
    "\n",
    "# Plot actual vs predicted for Random Forest\n",
    "ax2.scatter(y_test, rf_preds)\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax2.set_xlabel('Actual MPG')\n",
    "ax2.set_ylabel('Predicted MPG')\n",
    "ax2.set_title('Random Forest: Actual vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43dba1f",
   "metadata": {},
   "source": [
    "**Interpretation:**  To interpret these plots, keep in mind that the dotted red line represents a \"perfect fit\" model.  We don't expect every dot to be on the line, but we want them _close_ and _randomly spread_ around it (no patterns).  On the left plot (the linear model), we see a \"bent\" scatter of points compared to the line, indicating a bad fit.  On the right, the Random Forest (RF) behaves better, but we can see the over-prediction in the mid-range and then the beginnings of under-prediction happing at the top end (similar to what we see on the linear model's graph).  Again, the RF looks better, but leaves room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb6513",
   "metadata": {},
   "source": [
    "### Non-visual metrics\n",
    "\n",
    "Let's look at other regression metrics.\n",
    "\n",
    "Scikit-Learn provides several metrics appropriate for evaluating regression\n",
    "models.  You can see the list at\n",
    "<https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics>.\n",
    "\n",
    "We'll calculate some common metrics for both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1464842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for Linear Regression\n",
    "linear_mse = mean_squared_error(y_test, linear_preds)\n",
    "linear_rmse = np.sqrt(linear_mse)\n",
    "linear_mae = mean_absolute_error(y_test, linear_preds)\n",
    "linear_msd = np.mean(linear_preds-y_test)\n",
    "linear_r2 = r2_score(y_test, linear_preds)\n",
    "\n",
    "# Calculate metrics for Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_preds)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_mae = mean_absolute_error(y_test, rf_preds)\n",
    "rf_msd = np.mean(rf_preds-y_test)\n",
    "rf_r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "# Create a DataFrame to display the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest'],\n",
    "    'MSE': [linear_mse, rf_mse],\n",
    "    'RMSE': [linear_rmse, rf_rmse],\n",
    "    'MAE': [linear_mae, rf_mae],\n",
    "    'MSD': [linear_msd, rf_msd],\n",
    "    'R¬≤': [linear_r2, rf_r2]\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d277213",
   "metadata": {},
   "source": [
    "Let's understand these metrics:\n",
    "\n",
    "- **Mean Squared Error (MSE)**: The average of the squared differences between predicted and actual values. Lower is better.\n",
    "- **Root Mean Squared Error (RMSE)**: The square root of MSE. It's in the same units as the target variable, making it more interpretable. Lower is better.\n",
    "- **Mean Absolute Error (MAE)**: The average of the absolute differences between predicted and actual values. Lower is better.\n",
    "- **Mean Signed Deviation (MSD)**: The average of the differences between predicted and actual values, retaining the sign.  Closer to zero is better, and the sign indicates the direction of the bias (e.g. model is over-predicting vs. under-predicting).\n",
    "- **R¬≤ (Coefficient of Determination)**: Represents the proportion of variance in the dependent variable that is predictable from the independent variables. Ranges from 0 to 1, with higher values indicating better fit.\n",
    "\n",
    "Based on these metrics, the Random Forest model outperforms the Linear Regression model on our test set.  However, MSD reveals that the RF model is a bit more biased toward over-predicting the mpg than the linear model.  So, when RF makes a mistake, it is more likely to favor higher mpg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c121ae",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Some models can provide information about the importance of each featuer, allowing us to understand the underlying process better and perhaps perform feature selection to simplify our models.  Different models do this differently.\n",
    "\n",
    "**Linear Regression** models convey feature importance in the magnitude of the coefficients they compute for each feature.  You can access this information for Scikit-Learn `LinearRegression` models in the `coef_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will get the absolute values of the coefficients, since we don't care about direction here\n",
    "linear_feature_importance = np.abs(linear_model.coef_)\n",
    "# And then normalize them so that they sum to 1.0 just to make the scale easier to interpret.\n",
    "linear_feature_importance /= np.sum(linear_feature_importance)\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "linear_importance_df = pd.DataFrame({\n",
    "    'Feature': random_var_cols,\n",
    "    'Importance': linear_feature_importance\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "linear_importance_df = linear_importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=linear_importance_df)\n",
    "plt.title('Feature Importance from Linear Regression Model')\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401d741",
   "metadata": {},
   "source": [
    "üíπ We can see from this that \"model_year\" had the most impact on the linear model.  Looking back at the original scatterplots, we can see that model year does have a mostly-linear trend where mpg tends to increase in more recent years.\n",
    "\n",
    "\n",
    "\n",
    "The `RandomForestRegressor` model provides feature importance information in its `feature_importances_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the Random Forest model (it is already normalized to sum to 1.0).\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': random_var_cols,\n",
    "    'Importance': rf_feature_importance\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "plt.title('Feature Importances from Random Forest Model')\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f259e",
   "metadata": {},
   "source": [
    "ü§î Notice that the RF model has a different conclusion about which feature is most important, choosing \"displacement\".  Displacement seemed highly correlated with mpg in the original scatterplot, but the relationship is highly non-linear, and has redundancy with \"cylinders\" and \"horsepower\".  The RF was able to use this variable in spite of these challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8454908",
   "metadata": {},
   "source": [
    "## Working with categorical features\n",
    "\n",
    "So far, we've only used numeric features for our predictors. But the Auto MPG dataset also contains a categorical feature:\n",
    "\n",
    "* `origin` - three levels: [1, 2, 3] representing American, European, and Japanese cars respectively\n",
    "\n",
    "Let's convert this numeric encoding to more meaningful labels first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary\n",
    "origin_map = {1: 'American', 2: 'European', 3: 'Japanese'}\n",
    "\n",
    "# Create a new column with the mapped values\n",
    "auto_mpg['origin_name'] = auto_mpg['origin'].map(origin_map)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "auto_mpg[['origin', 'origin_name']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b078265",
   "metadata": {},
   "source": [
    "Now let's visualize how MPG varies by origin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='origin_name', y='mpg', data=auto_mpg)\n",
    "plt.title('MPG by Car Origin')\n",
    "plt.xlabel('Origin')\n",
    "plt.ylabel('MPG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32dbfa",
   "metadata": {},
   "source": [
    "We can see that there are differences in MPG based on the car's origin. Japanese cars tend to have higher MPG, followed by European cars, with American cars having the lowest MPG on average.\n",
    "\n",
    "To include this categorical variable in our regression models, we need to encode it. One common approach is **_one-hot encoding_**.\n",
    "\n",
    "**_One-hot encoding_** is an encoding technique in which a variable with $N$ levels is split into $N$ new _pseudo-variables_ where each is a binary variable encoded as 1 or 0.\n",
    "\n",
    "Let's see how our `origin` variable might look if it were one-hot encoded:\n",
    "\n",
    "**Before**\n",
    "\n",
    "    mpg  cylinders  displacement  ...  origin  car_name\n",
    "    20.5  6         200.0         ...  1       chevrolet malibu\n",
    "    15.0  8         350.0         ...  1       buick skylark 320\n",
    "    22.0  4         121.0         ...  2       volkswagen 411 (sw)\n",
    "    26.0  4         98.00         ...  2       fiat 124 sport coupe\n",
    "    32.0  4         71.00         ...  3       toyota corolla 1200\n",
    "    24.0  4         120.0         ...  3       honda civic\n",
    "\n",
    "**After**\n",
    "\n",
    "    mpg  cylinders  displacement  ...  origin_American  origin_European  origin_Japanese  car_name\n",
    "    20.5  6         200.0         ...  1                0                0                chevrolet malibu\n",
    "    15.0  8         350.0         ...  1                0                0                buick skylark 320\n",
    "    22.0  4         121.0         ...  0                1                0                volkswagen 411 (sw)\n",
    "    26.0  4         98.00         ...  0                1                0                fiat 124 sport coupe\n",
    "    32.0  4         71.00         ...  0                0                1                toyota corolla 1200\n",
    "    24.0  4         120.0         ...  0                0                1                honda civic\n",
    "\n",
    "\n",
    "**Here's the code:**\n",
    "\n",
    "Pandas can do this in a dataframe by using the `get_dummies()` method.  You provide a prefix\n",
    "(like `\"origin\"`) and the existing levels are used to complete the new column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fa0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rows = [253, 1, 77, 114, 131, 149] # this lets us select the same cars shown above\n",
    "auto_mpg_encoded = pd.get_dummies(        # get_dummies converts to one-hot encoding\n",
    "    auto_mpg, columns=[\"origin_name\"], prefix=\"origin\", dtype=int\n",
    ")\n",
    "auto_mpg_encoded.loc[sample_rows][['mpg', 'origin_American', 'origin_European', 'origin_Japanese', 'car_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3887ae8e",
   "metadata": {},
   "source": [
    "Now let's use these one-hot encoded features in our regression models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns including one-hot encoded origin\n",
    "all_features = random_var_cols + ['origin_American', 'origin_European', 'origin_Japanese']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d56a6",
   "metadata": {},
   "source": [
    "Now we will evaluate each of our models with a 5-fold CV like we did in the beginning, and compare the original features to the ones with origin information included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe372b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function so we don't have to repeat this code too much\n",
    "def do_evaluation(model, X, y, caption):\n",
    "    scores = cross_validate( model, X, y, scoring=scoring_metrics)\n",
    "    print(\n",
    "        f\"{caption}\\n\"\n",
    "        f\"mean R¬≤ : {scores['test_r2'].mean():0.3f}, std: {scores['test_r2'].std():0.3f}\\n\"\n",
    "        f\"mean MAE: {-scores['test_mae'].mean():0.1f} mpg, std: {scores['test_mae'].std():0.2f} mpg.\\n\"\n",
    "    )  # print mean and standard deviation of score metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c278e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_evaluation(LinearRegression(), X=auto_mpg[random_var_cols], y=auto_mpg[target_col], caption=\"Linear Regression without origin info:\")\n",
    "do_evaluation(LinearRegression(), X=auto_mpg_encoded[all_features], y=auto_mpg_encoded[target_col], caption=\"Linear Regression including origin info:\")\n",
    "\n",
    "print(\"---\\n\")\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "do_evaluation(LinearRegression(), X=poly.fit_transform(auto_mpg[random_var_cols]), y=auto_mpg[target_col], caption=\"Polynomial (d=2) Regression without origin info:\")\n",
    "do_evaluation(LinearRegression(), X=poly.fit_transform(auto_mpg_encoded[all_features]), y=auto_mpg_encoded[target_col], caption=\"Polynomial (d=2) Regression including origin info:\")\n",
    "\n",
    "print(\"---\\n\")\n",
    "\n",
    "do_evaluation(RandomForestRegressor(random_state=1), X=auto_mpg[random_var_cols], y=auto_mpg[target_col], caption=\"Random Forest regression without origin info:\")\n",
    "do_evaluation(RandomForestRegressor(random_state=1), X=auto_mpg_encoded[all_features], y=auto_mpg_encoded[target_col], caption=\"Random Forest regression including origin info:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb2e52",
   "metadata": {},
   "source": [
    "Including the origin as a categorical feature has improved our model performance in the linear regression and quadratic models, but not significantly.  The RF model was mostly unchanged by the addition of this variable.  \n",
    "\n",
    "However, categorical variables can be very important in some datasets!  Consider encoding them and using them in the model; you can evaluate whether or not it was worthwhile before training your final model version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad00e4f",
   "metadata": {},
   "source": [
    "#### There's More Than One Way to Do It\n",
    "\n",
    "You can also use the `OneHotEncoder` from Scikit-Learn to encode categorical variables. It's particularly useful when you don't want to modify your original dataframe and prefer to create a \"data pipeline\" for preprocessing your data during training or inference.\n",
    "\n",
    "In fact, there are _several_ other approaches to encoding categorical values.  \n",
    "\n",
    "You can learn a lot more here: <https://www.kaggle.com/code/arashnic/an-overview-of-categorical-encoding-methods>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c48a3",
   "metadata": {},
   "source": [
    "## Thank You!\n",
    "\n",
    "This notebook in tutorial and completed form is available at:\n",
    "\n",
    "<https://jcausey-astate.github.io/ASRI-2025/>\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "asri-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
