{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac4e0f01",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jcausey-astate/ASRI-2025/blob/main/python_intermediate_classification_ASRI25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea087c",
   "metadata": {
    "id": "4bea087c"
   },
   "source": [
    "# Classification in Python (Intermediate)\n",
    "## ASRI 2025\n",
    "\n",
    "\n",
    "![Classification in Python (Intermediate)](https://jcausey-astate.github.io/ASRI-2025/images/classification_in_python_title_card.svg)\n",
    "\n",
    "![The Palmer Archipelago penguins. Artwork by @allison_horst.](https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png)\n",
    "\n",
    "The notebook uses the following modules:\n",
    "\n",
    "* `matplotlib`  : Provides basic graphing/charting.\n",
    "* `numpy`       : Allows matrix and vector/array math.\n",
    "* `pandas`      : Provides DataFrame functionality.\n",
    "* `seaborn`     : Works with `matplotlib` to provide nicer graphs.\n",
    "* `sklearn`     : Scikit-Learn provides machine learning and data manipulation tools.\n",
    "\n",
    "We will rely heavily on the Scikit-Learn library for models, metrics, and\n",
    "experimental design tools.  See the full documentation for this fantastic\n",
    "library at <https://scikit-learn.org>.\n",
    "\n",
    "---\n",
    "\n",
    "## First, some terms and definitions:\n",
    "\n",
    "**_Classification_** is the process of determining a _categorical label_ given\n",
    "the _random variables_ for a given _sample_.\n",
    "\n",
    "**_Categorical_** values are allowed to take on only a finite (usually small)\n",
    "set of values.  Categorical variables are usually non-numeric, but are sometimes\n",
    "encoded as numbers.  Sometimes we refer to values of this type as _labels_,\n",
    "_factors_, or _classes_.\n",
    "\n",
    "**_Continuous_** values are numeric values that are allowed to take on any value within\n",
    "some range.\n",
    "\n",
    "A **_sample_** consists of all of the experimental information gathered for one\n",
    "item in the dataset.  Sometimes a _sample_ is called an _object_ or _item_.\n",
    "Usually samples are arranged as _rows_ in tabular datasets (CSV files, Excel\n",
    "spreadsheets, or similar).\n",
    "\n",
    "A **_random variable_**, sometimes called an _input variable_, _measurement_, or\n",
    "_feature_, is the recorded value for some property of the sample that was\n",
    "measured in the experiment, e.g. \"height\", \"age\", \"flower color\", etc.\n",
    "\n",
    "#### You have a _classification_ problem if the dependent variable (output value) you are trying to predict is _categorical_.\n",
    "\n",
    "We will focus first on classification problems where the random variables are\n",
    "_continuous_.\n",
    "\n",
    "At the end, a section is provided with some tips for working with random variables that\n",
    "are _categorical_.\n",
    "\n",
    "___\n",
    "\n",
    "## Let's see some code!\n",
    "\n",
    "First, we have to import the modules, objects, and functions we will be using\n",
    "in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957d656",
   "metadata": {
    "id": "0957d656",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f67c8",
   "metadata": {
    "id": "fc0f67c8"
   },
   "source": [
    "### The Dataset\n",
    "\n",
    "‚ÑπÔ∏è  The `seaborn` package has some sample datasets included.\n",
    "\n",
    "For this tutorial, we will use the \"Palmer Penguins\" dataset, which is called\n",
    "`penguins` in the Seaborn index.  We can load it with the `load_dataset()`\n",
    "function.  It will load up as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a78402",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c0a78402",
    "outputId": "38d4ca17-2fe3-4da3-c62f-0ea8254628c1"
   },
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8a1fd",
   "metadata": {
    "id": "14a8a1fd"
   },
   "source": [
    "The **species** column contains the value that we want to predict (it is our\n",
    "_label_ column).  Although we could use all the other columns as random\n",
    "variables (predictors), we will only focus on the numeric values for this part\n",
    "of the tutorial.\n",
    "\n",
    "It will make things easier if we create variables to contain the name of the\n",
    "label column and the random variables.  These can be used when we interact with\n",
    "Pandas DataFrames to quickly select those columns by name.  This way, we don't\n",
    "have to type the list of names often, and we don't have to create a different\n",
    "data structure that only contains our variables of interest (although you\n",
    "_could_ also do it that way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48608841",
   "metadata": {
    "id": "48608841"
   },
   "outputs": [],
   "source": [
    "label_col = \"species\"\n",
    "random_var_cols = [\n",
    "    \"bill_length_mm\",\n",
    "    \"bill_depth_mm\",\n",
    "    \"flipper_length_mm\",\n",
    "    \"body_mass_g\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77d0c5",
   "metadata": {
    "id": "8c77d0c5"
   },
   "source": [
    "Let's use the `info()` DataFrame method to see what kinds of values we have, and\n",
    "whether there are any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4a646",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7c4a646",
    "outputId": "86154360-d4f1-407f-cb92-57a4c406bce7"
   },
   "outputs": [],
   "source": [
    "penguins.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a317f",
   "metadata": {
    "id": "397a317f"
   },
   "source": [
    "Notice that there are some missing values.  We care most about the numeric\n",
    "columns for this example, so we want to drop any rows with missing values in\n",
    "those columns.\n",
    "\n",
    "The `dropna()` method can do this.  The `subset` parameter lets us specify which\n",
    "columns we care about (the random variables we specified earlier).  We use\n",
    "`axis=0` to indicate that we want to drop _rows_, not columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cd584",
   "metadata": {
    "id": "692cd584"
   },
   "outputs": [],
   "source": [
    "# TODO: Use `dropna()` to remove _rows_ with missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0bef6",
   "metadata": {
    "id": "6bf0bef6"
   },
   "source": [
    "### üìä Visualize Early, Visualize Often\n",
    "\n",
    "Let's take a look at the dataset.  We will plot two different 'views' for\n",
    "comparison.  the first will compare bill length with bill depth, and the second\n",
    "will compare bill length with flipper length.\n",
    "\n",
    "We can color the datapoints according to species so that we can visually see how\n",
    "separable the different classes might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b2afc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "8a5b2afc",
    "outputId": "53a8be54-d1a5-405b-b58f-3107305b4f38"
   },
   "outputs": [],
   "source": [
    "# create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "plt.suptitle(\"Separating penguin species by bill measurements and/or flipper length.\")\n",
    "\n",
    "# create first scatterplot using Seaborn\n",
    "sns.scatterplot(\n",
    "    data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\", ax=ax1\n",
    ")\n",
    "ax1.set_title(\"Bill Length vs Bill Depth (mm)\")\n",
    "\n",
    "# create second scatterplot just like the first, but with different columns\n",
    "sns.scatterplot(\n",
    "    data=penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\", hue=\"species\", ax=ax2\n",
    ")\n",
    "ax2.set_title(\"Bill Length vs Flipper Length (mm)\")\n",
    "\n",
    "# adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "\n",
    "# show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0b581",
   "metadata": {
    "id": "a8c0b581"
   },
   "source": [
    "If we look at these plots, it seems we can probably do a pretty good job of\n",
    "separating the three classes.  We see that you could even get pretty good\n",
    "performance by drawing a few lines to separate the groups (in other words, a\n",
    "simple linear model might work reasonably well).\n",
    "\n",
    "To see what a harder classification problem might look like, let's draw another\n",
    "scatterplot where we compare the flipper length and the body mass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b6e18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "bd7b6e18",
    "outputId": "d664db4e-f5f7-437d-eba0-d744ffcd4c67"
   },
   "outputs": [],
   "source": [
    "# TODO: Use Seaborn to `scatterplot` the penguins data with x=\"flipper_length_mm\" and \n",
    "# y=\"body_mass_g\".  Use \"species\" to provide the hue.\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"A more difficult problem...\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e69252",
   "metadata": {
    "id": "35e69252"
   },
   "source": [
    "In this plot, it is very hard to see how we could separate the \"Adelie\" group\n",
    "from the \"Chinstrap\" group.  There is even some mixing between the \"Chinstrap\"\n",
    "and \"Gentoo\" groups.\n",
    "\n",
    "‚ú® Choosing the right random variables for prediction is **vital**.  This is why\n",
    "it is a good idea to get to know your dataset early in the process!  **Visualize\n",
    "early, visualize often!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e888c",
   "metadata": {
    "id": "f06e888c"
   },
   "source": [
    "## Let's see how well we can classify with a linear model.\n",
    "\n",
    "First, we examine the `LogisticRegression` model (which is actually a\n",
    "classification model -- don't let the name fool you).\n",
    "\n",
    "Based on the graphs we plotted above, let's use the bill length and depth as our\n",
    "random variables.  (‚ÑπÔ∏è : We could absolutely use all four random variables and\n",
    "it would probably do better, but using just two gives us a chance to discuss the\n",
    "performance with a very simple model.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb70c3",
   "metadata": {
    "id": "0ecb70c3",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "random_var_cols = [\n",
    "    \"bill_length_mm\",\n",
    "    \"bill_depth_mm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bd5a4",
   "metadata": {
    "id": "b59bd5a4"
   },
   "source": [
    "To quickly determine if it will be suitable to this problem, we can use the\n",
    "`cross_val_score()` function from Scikit-Learn.  This function wraps up a\n",
    "**lot** of functionality.  It will set up a [_k-fold cross validation_ experiment](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "(with default of $k=5$, for five-fold CV).  It will take the model of your\n",
    "choice and automatically _train_ the model for each training fold, then\n",
    "_predict_ the test cases and _score_ the predictions on the test folds (with the\n",
    "_accuracy_ metric by default).\n",
    "\n",
    "The scores for each fold are returned.  We can calculate and report the mean\n",
    "score over all five folds along with the standard deviation of the scores to see\n",
    "whether the model is able to do a good job in general, and how much variation we\n",
    "would expect for different training sets.  Models should have high accuracy, and\n",
    "a low standard deviation would indicate that the model generalizes to new data\n",
    "very well.  (A high standard deviation would indicate the model is unstable and\n",
    "doesn't generalize well.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0df7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59b0df7c",
    "outputId": "72cbea2d-1cd7-4ce5-d7af-01ebf1c5766c"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    LogisticRegression(max_iter=500), X=penguins[random_var_cols], y=penguins[label_col]\n",
    ")\n",
    "print(\n",
    "    f\"mean: {scores.mean():0.3f}, std: {scores.std():0.3f}\"\n",
    ")  # print mean and standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee561d2",
   "metadata": {
    "id": "bee561d2"
   },
   "source": [
    "üéâ **Wow!** The linear model does a really good job on this problem!\n",
    "\n",
    "OK, that isn't really surprising since we looked at the data first and we could\n",
    "see that some combinations of our random variables provided good linear\n",
    "separation between the groups.  Still, it's nice to see our intuition was\n",
    "correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939bb13",
   "metadata": {
    "id": "9939bb13"
   },
   "source": [
    "Let's take a look at a different kind of model, just for comparison.  A Random\n",
    "Forest model is a non-linear model that works well for lots of tasks.\n",
    "Scikit-Learn provides one called `RandomForestClassifier`.\n",
    "\n",
    "Let's try it in exactly the same experimental setup we used for the linear\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d88982",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7d88982",
    "outputId": "30eb70b2-f7eb-4518-ca97-f519423bedbe"
   },
   "outputs": [],
   "source": [
    "# TODO: perform a cross_val_score() using a RandomForestClassifier (and set the \n",
    "# random_state to 1)).  Store the results in `scores` so that the print statement\n",
    "# will print it as expected.\n",
    "\n",
    "\n",
    "print(f\"mean: {scores.mean():0.3f}, std: {scores.std():0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17e1c1",
   "metadata": {
    "id": "ef17e1c1"
   },
   "source": [
    "Here, the random forest did about the same as the linear model (especially if we\n",
    "take the standard deviations of scores into account).\n",
    "\n",
    "If we wanted to pick between these two models for this problem, we should\n",
    "probably choose the _simpler_ one -- the logistic regression model.\n",
    "\n",
    "üí° The **_Principle of Parsimony_** says that given the choice between multiple\n",
    "models with similar performance, the best choice is usually the simplest model.\n",
    "\n",
    "‚ÑπÔ∏è  One note:\n",
    "\n",
    "We used `random_state=1` to _seed_ the random number generator within the model,\n",
    "causing it to produce identical results if we train it again on the same data.\n",
    "Random forests (as implied by their name) rely on some randomness during\n",
    "training, so you don't expect to get the same performance every time.  This\n",
    "makes **reproducible results** difficult.\n",
    "\n",
    "üí° By seeding the random state, we \"lock\" it to a specific outcome (assuming no\n",
    "external changes).  This way, others can reproduce our results in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca864b",
   "metadata": {
    "id": "dcca864b"
   },
   "source": [
    "## Exploring more ways to characterize classifier performance.\n",
    "\n",
    "### üìä Visualize!\n",
    "\n",
    "When the model is making incorrect predictions, sometimes we want to know _which\n",
    "samples the model predicts incorrectly_.  This can help us diagnose whether the\n",
    "model is doing the best it can, whether the model is doing strange things, or\n",
    "even whether there might be a problem with the dataset itself.\n",
    "\n",
    "Generally, a good starting point to diagnosing the mis-predicted values from a\n",
    "model is for us to _visualize_ them in some way.   Since this problem is easy to\n",
    "visualize as a 2-D scatterplot, we will use that as a way to see which samples\n",
    "the model is getting right vs. wrong.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3cead0",
   "metadata": {
    "id": "7a3cead0"
   },
   "source": [
    "To start, let's just split the dataset into a simple 80% / 20% train / test\n",
    "split.  That means that we will reserve 20% of the samples for the test set, and\n",
    "the other 80% will be used for training.  Scikit-Learn has a simple function for\n",
    "doing this (`train_test_split()`).\n",
    "\n",
    "The function returns a training and testing dataframe (or matrix) given the\n",
    "original full dataset and the fraction you want to hold out for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198959e",
   "metadata": {
    "id": "4198959e"
   },
   "outputs": [],
   "source": [
    "# TODO: use `train_test_split()` to split the penguins data with a test_size\n",
    "# of 0.20 (20%) and random_state=2.  The results should be stored in \n",
    "# train_df, test_df for later use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4201078",
   "metadata": {
    "id": "c4201078"
   },
   "source": [
    "We'll use the `LogisticRegression` model again, training it on the \"train\"\n",
    "partition (using the `fit()` method).  Then, we'll predict the \"test\" samples\n",
    "and calculate the (balanced) accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaea2f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeaea2f9",
    "outputId": "cf24b6b7-0106-475a-cab1-d035e9d1b4a2"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500).fit(\n",
    "    X=train_df[random_var_cols], y=train_df[label_col]\n",
    ")\n",
    "preds = model.predict(test_df[random_var_cols])\n",
    "ground_truth = test_df[label_col]\n",
    "print(f\"{balanced_accuracy_score(ground_truth, preds):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9221180e",
   "metadata": {
    "id": "9221180e"
   },
   "source": [
    "Now, let's create the scatterplot that will show _which samples were predicted\n",
    "**incorrectly**_.\n",
    "\n",
    "We can use color to indicate correct (green) and incorrect (red) predictions.\n",
    "We will also use different marker shapes to indicate the true class label so\n",
    "that we can see which ones are being predicted incorrectly and get a sense for\n",
    "_why_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48d585",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "ad48d585",
    "outputId": "78e7a6aa-65c5-4631-a5d2-d69b9705929c"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig = sns.scatterplot(\n",
    "    data=test_df,\n",
    "    x=\"bill_length_mm\",\n",
    "    y=\"bill_depth_mm\",\n",
    "    hue=(preds == ground_truth),\n",
    "    style=list(test_df[label_col].values),\n",
    "    markers=[\"o\", \"D\", \"s\"],\n",
    "    palette=[\"red\", \"green\"],\n",
    ")\n",
    "fig.legend()  # weird kludge:  The \"species\" title is shown by default, but just calling `legend()` removes it.  Why? ü§∑\n",
    "plt.title(\"Correct (green) and Incorrect (red) predictions.\")\n",
    "print(test_df[label_col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcbaeb",
   "metadata": {
    "id": "0ddcbaeb"
   },
   "source": [
    "The green dots are samples that were correctly predicted and the red dots are\n",
    "incorrect predictions.  There are only four incorrect predictions.  Three of\n",
    "those are near the \"border\" between the two visual \"clusters\".  That makes sense\n",
    "-- class mixing obviously occurs here.  The other one is a Gentoo penguin that\n",
    "was incorrectly predicted (probably as a Chinstrap, since there are Chinstrap\n",
    "penguins nearby).\n",
    "\n",
    "**At this point, we will make the problem harder.**  Why?  Well, it will be more\n",
    "interesting to explore correct / incorrect predictions if the model is not quite\n",
    "so good.\n",
    "\n",
    "The flipper length and body mass do not combine to give very good separation, so\n",
    "we will choose those as our random variables from this point forward.  \n",
    "\n",
    "ü§î Of course, we would never choose _worse_ predictors in any real analysis, but doing this can be useful as a learning exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ced79",
   "metadata": {
    "id": "cc7ced79"
   },
   "outputs": [],
   "source": [
    "random_var_cols = [\"flipper_length_mm\", \"body_mass_g\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9cce6",
   "metadata": {
    "id": "72c9cce6"
   },
   "source": [
    "Let's see how our new random variables perform with the same linear model as\n",
    "before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05da45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc05da45",
    "outputId": "7144f453-74ea-44d5-802c-feaa3948093a"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    LogisticRegression(max_iter=500), X=penguins[random_var_cols], y=penguins[label_col]\n",
    ")\n",
    "print(f\"mean: {scores.mean():0.3f}, std: {scores.std():0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e8152",
   "metadata": {
    "id": "e09e8152"
   },
   "source": [
    "Much worse performance! üò¶  That's bad... But more interesting for exploring the\n",
    "performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90388963",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90388963",
    "lines_to_next_cell": 0,
    "outputId": "1f7b8eb3-42e4-45e2-ae1f-e55d6c3883c1"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    RandomForestClassifier(random_state=1),\n",
    "    X=penguins[random_var_cols],\n",
    "    y=penguins[label_col],\n",
    ")\n",
    "print(f\"mean: {scores.mean():0.3f}, std: {scores.std():0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725368a",
   "metadata": {
    "id": "c725368a"
   },
   "source": [
    "The random forest did quite a bit better here.  We saw that these two variables\n",
    "don't provide an obvious path for _linear_ separation, but the random forest is\n",
    "not limited to linear decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229c5de",
   "metadata": {
    "id": "a229c5de"
   },
   "source": [
    "We will use our simple 80%/20% train/test split from earlier and train the\n",
    "linear model using the new (worse) combination of random variables.  First,\n",
    "train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0616b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c0616b1",
    "outputId": "91728ea6-0861-46c1-c764-cee4a205e2ca"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500).fit(\n",
    "    X=train_df[random_var_cols], y=train_df[label_col]\n",
    ")\n",
    "preds = model.predict(test_df[random_var_cols])\n",
    "ground_truth = test_df[label_col]\n",
    "print(f\"{balanced_accuracy_score(ground_truth, preds):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9661f6",
   "metadata": {
    "id": "7e9661f6"
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Now, we can use another visualization technique to discuss the performance\n",
    "characteristics.  This technique is called a _confusion matrix_.  It shows the\n",
    "number of samples from each true label that were predicted as each possible\n",
    "output label.  Seaborn makes very nice confusion matrix plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f996564",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "8f996564",
    "lines_to_next_cell": 2,
    "outputId": "65552943-8390-4b94-d5e8-780435f98617"
   },
   "outputs": [],
   "source": [
    "# TODO: call `confusion_matrix() with ground_truth and preds (in that order).\n",
    "# Store the result in a variable called `cm` for later use.\n",
    "\n",
    "\n",
    "# plot the confusion matrix using seaborn heatmap\n",
    "sns.set_theme(font_scale=1.4)  # adjust font size\n",
    "labels = model.classes_\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt=\"g\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels\n",
    ")\n",
    "\n",
    "# add axis labels and title\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03def06",
   "metadata": {
    "id": "b03def06"
   },
   "source": [
    "**Correct** predictions appear along the diagonal (upper-left to lower-right).\n",
    "All of the other squares represent **incorrect** predictions.\n",
    "\n",
    "Here, the linear model did very well with predicting Gentoo penguins when it saw\n",
    "a _real_ Gentoo.  But it also incorrectly guessed that 3 Chinstraps and 1 Adelie\n",
    "were Gentoos as well (**_False Positives_**).\n",
    "\n",
    "As for the Chinstraps, we correctly classified 6 of them, but we incorrectly\n",
    "labeled 7 Chinstraps as Adelie and 3 as Gentoo (**_False Negatives_**).\n",
    "\n",
    "### Non-visual metrics\n",
    "\n",
    "Let's look at other classification metrics.\n",
    "\n",
    "Scikit-Learn provides several metrics appropriate for evaluating classification\n",
    "models.  You can see the list at\n",
    "<https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics>.\n",
    "\n",
    "We will start with the `classification_report()` function, which combines\n",
    "several popular metrics into a single report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bee913",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19bee913",
    "outputId": "740cb532-bca3-4b55-e123-39aa9dd2dda9"
   },
   "outputs": [],
   "source": [
    "# We get precision, recall, and f1-score from the classification report.\n",
    "# You can also get these individually from functions in sklearn.metrics.\n",
    "\n",
    "# TODO: print the result returned by calling classification_report() with ground_truth and preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62ab21",
   "metadata": {
    "id": "6e62ab21"
   },
   "source": [
    "**What about binary classification?**\n",
    "\n",
    "So far, we've been performing _multi-class_ classification:  There were three\n",
    "possible classes {Adelie, Chinstrap, Gentoo}, and each sample could only be a\n",
    "member of a single class.\n",
    "\n",
    "Many classification problems can be expressed as _binary_ classification\n",
    "problems.  That just means that there are _two_ classes (and all samples must be\n",
    "one or the other, but not both).\n",
    "\n",
    "Some metrics make sense with binary problems, but not with multi-class problems.\n",
    "Let's change our dataset to make it into a binary classification problem.  To do\n",
    "this, we will simply change classification to answer the question \"Chinstrap or\n",
    "not?\".  So, our new labels will be {Chinstrap, Other}.  To do this, we will make\n",
    "a copy of our dataset and modify the `species` column to reflect the binary\n",
    "labeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf1eca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeaf1eca",
    "outputId": "85fa184e-a4f8-4ebb-9ce3-5fe5b9313a88"
   },
   "outputs": [],
   "source": [
    "# Make a binary dataset by splitting the \"Adelie\" and \"Gentoo\" penguins\n",
    "# away from the \"Chinstrap\" penguins.\n",
    "binary_penguins = penguins.copy()\n",
    "binary_penguins.loc[binary_penguins[\"species\"] != \"Chinstrap\", \"species\"] = \"Other\"\n",
    "\n",
    "# Create new train/test split with the new dataset.  (80%/20% as before)\n",
    "b_train_df, b_test_df = train_test_split(\n",
    "    binary_penguins, test_size=0.20, random_state=2, stratify=binary_penguins[\"species\"]\n",
    ")\n",
    "# Fit a linear model to the new dataset\n",
    "model = LogisticRegression(max_iter=500).fit(\n",
    "    X=b_train_df[random_var_cols], y=b_train_df[label_col]\n",
    ")\n",
    "# And predict on the test set.\n",
    "preds = model.predict(b_test_df[random_var_cols])\n",
    "ground_truth = b_test_df[label_col]\n",
    "print(f\"Acc: {accuracy_score(ground_truth, preds):0.3f}\")\n",
    "print(classification_report(ground_truth, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbaafef",
   "metadata": {
    "id": "cdbaafef"
   },
   "source": [
    "We can see that the binary accuracy is about 78%.\n",
    "\n",
    "#### Receiver Operating Characteristic (ROC) Curve and Area Under the ROC Curve (AUC)\n",
    "\n",
    "A common way of comparing binary classifier is by **visually** interpreting a\n",
    "performance curve called the **_Receiver Operating Characteristic_** (ROC) curve,\n",
    "or by **numerically** interpreting the area under the ROC curve (AUC or AUROC).\n",
    "\n",
    "To create an ROC curve, we need to predict the _probability_ that each sample\n",
    "belongs to the \"positive\" class.  In Scikit-Learn compatible models, you can use\n",
    "the `predict_proba()` method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fdec8",
   "metadata": {
    "id": "552fdec8",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# TODO: call the `predict_proba()` method on the model, givin the b_test_df \n",
    "# and selecting the random_var_cols.  The result should be stored in a variable\n",
    "# named `probas` for later use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b9a2b",
   "metadata": {
    "id": "6b8b9a2b"
   },
   "source": [
    "`predict_proba` gives a score for each class.  For binary problems, we only need\n",
    "the score for the first class (the \"positive\" class).  We will select that by\n",
    "slicing off the first column from all the rows in `probas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b723d14",
   "metadata": {
    "id": "5b723d14"
   },
   "outputs": [],
   "source": [
    "probas_pos = probas[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551a2d1",
   "metadata": {
    "id": "c551a2d1"
   },
   "source": [
    "We can make a binary (1,0) ground truth by comparing the labels with the first\n",
    "class in our model (which we will consider the \"positive\" class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167f9b9",
   "metadata": {
    "id": "a167f9b9"
   },
   "outputs": [],
   "source": [
    "ground_truth = b_test_df[label_col] == model.classes_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd287cf",
   "metadata": {
    "id": "4fd287cf"
   },
   "source": [
    "The ROC curve plots the True-Positive Rate (tpr) against the False-Positive Rate\n",
    "(fpr) given all possible thresholds (from 0.0 to 1.0).  The `roc_auc_score()`\n",
    "function from Scikit-Learn can compute the tpr and fpr scores for us, given the\n",
    "ground truth and predicted probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c628eb2",
   "metadata": {
    "id": "8c628eb2"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(ground_truth, probas_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c41ac1",
   "metadata": {
    "id": "e4c41ac1"
   },
   "source": [
    "And the `roc_auc_score()` will calculate the area under the ROC curve, given the\n",
    "same information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868d8f2",
   "metadata": {
    "id": "e868d8f2"
   },
   "outputs": [],
   "source": [
    "auc = roc_auc_score(ground_truth, probas_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85318c6",
   "metadata": {
    "id": "f85318c6"
   },
   "source": [
    "Now, let's plot the ROC curve and display the AUC in the legend using\n",
    "Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91524a4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "91524a4d",
    "lines_to_next_cell": 2,
    "outputId": "4b90122f-bed5-4999-ce38-8e7387414f1c"
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, label=f\"auc={auc:0.3f}\")\n",
    "plt.xlabel(\"fpr\")\n",
    "plt.ylabel(\"tpr\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66632e3d",
   "metadata": {
    "id": "66632e3d"
   },
   "source": [
    "Since we might want to compare multiple models on the same figure, let's make a\n",
    "function that will take a dictionary of the form `{name: model}` of models,\n",
    "the training and testing samples and labels, and plot the ROC curve for all models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe445916",
   "metadata": {
    "id": "fe445916"
   },
   "outputs": [],
   "source": [
    "# plots multiple models on the same ROC plot and compare them visually:\n",
    "def multi_auc_comparison(models, X_train, y_train, X_test, y_test):\n",
    "    for name in models:\n",
    "        model = models[name]\n",
    "        model.fit(X_train, y_train)\n",
    "        probas = model.predict_proba(X_test)[:, 0]\n",
    "        fpr, tpr, _ = roc_curve(y_test, probas)\n",
    "        auc = roc_auc_score(y_test, probas)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} AUC: {auc:0.3f}\")\n",
    "        plt.xlabel(\"fpr\")\n",
    "        plt.ylabel(\"tpr\")\n",
    "        plt.title(\"ROC Curve Comparision\")\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb984aec",
   "metadata": {
    "id": "cb984aec"
   },
   "source": [
    "Let's see it in action by comparing the linear logistic regression model to the\n",
    "random forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a3f55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "569a3f55",
    "lines_to_next_cell": 0,
    "outputId": "4fb6eec6-95ef-490f-e720-5285f1bc0663"
   },
   "outputs": [],
   "source": [
    "multi_auc_comparison(\n",
    "    {\n",
    "        \"LR\": LogisticRegression(max_iter=500),\n",
    "        \"RF\": RandomForestClassifier(random_state=1),\n",
    "    },\n",
    "    b_train_df[random_var_cols],\n",
    "    b_train_df[label_col],\n",
    "    b_test_df[random_var_cols],\n",
    "    ground_truth,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310dcd4",
   "metadata": {
    "id": "e310dcd4"
   },
   "source": [
    "Generally, the higher AUC is better, but we can see from the ROC curve plot that\n",
    "there is some tradeoff in the performance characteristics (tradeoff between\n",
    "false positives and false negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa5b4b",
   "metadata": {
    "id": "0ffa5b4b"
   },
   "source": [
    "## Working with categorical features\n",
    "\n",
    "So far, we only used numeric features for our predictors.  But, the Palmer Penguins\n",
    "dataset also contains some _categorical_ features:\n",
    "\n",
    "* `island` - three levels: ['Biscoe', 'Dream', 'Torgersen']\n",
    "* `sex` - two levels ['Male', 'Female']\n",
    "\n",
    "Binary variables (with only two levels) can be re-encoded as 0 and 1 and used essentially the same\n",
    "as a continuous numeric variable.\n",
    "\n",
    "Variables with more than two levels require a little more thought.  You _could_ encode them using\n",
    "different numeric levels (e.g. {-1, 0, 1}), but this might not always work well.  A common approach to\n",
    "multi-level categorical variables is to **_one-hot encode_** them.\n",
    "\n",
    "**_One-hot encoding_** is an encoding technique in which a variable with $N$ levels is split into $N$ new _pseudo-variables_ where each is a binary variable encoded as 1 or 0.\n",
    "\n",
    "Let's see how our `island` variable might look if it were one-hot encoded:\n",
    "\n",
    "**Before**\n",
    "\n",
    "    species island    bill_length_mm bill_depth_mm ...\n",
    "    Adelie  Biscoe    38.8           17.2          ...\n",
    "    Adelie  Torgersen 40.3           18.0          ...\n",
    "    Adelie  Torgersen 39.1           18.7          ...\n",
    "    Adelie  Biscoe    37.8           18.3          ...\n",
    "    Adelie  Dream     39.5           17.8          ...\n",
    "    Adelie  Biscoe    38.2           18.1          ...\n",
    "    Adelie  Torgersen 36.7           19.3          ...\n",
    "    Adelie  Dream     37.2           18.1          ...\n",
    "\n",
    "**After**\n",
    "\n",
    "    species island_Biscoe island_Dream island_Torgersen bill_length_mm bill_depth_mm ...\n",
    "    Adelie  1             0            0                38.8           17.2          ...\n",
    "    Adelie  0             0            1                40.3           18.0          ...\n",
    "    Adelie  0             0            1                39.1           18.7          ...\n",
    "    Adelie  1             0            0                37.8           18.3          ...\n",
    "    Adelie  0             1            0                39.5           17.8          ...\n",
    "    Adelie  1             0            0                38.2           18.1          ...\n",
    "    Adelie  0             0            1                36.7           19.3          ...\n",
    "    Adelie  0             1            0                37.2           18.1          ...\n",
    "\n",
    "\n",
    "**Heres the code:**\n",
    "\n",
    "Pandas can do this in a dataframe by using the `get_dummies()` method.  You provide a prefix\n",
    "(like `\"island\"`) and the existing levels are used to complete the new column names.\n",
    "\n",
    "By default, the values will be Boolean (True, False), but we can use `dtype=int` to make them\n",
    "integers.  (‚ÑπÔ∏è You don't have to do this - the Boolean values will convert automatically when needed. We do it here just to be explicit about how the categories are becoming numbers.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750665f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2750665f",
    "outputId": "412bbe73-0284-4337-89d0-04e46916bfb3"
   },
   "outputs": [],
   "source": [
    "# TODO: Call the `get_dummies()` method on the penguins data, selecting the 'island' column\n",
    "# with columns=['island'].  Set the prefix 'island', and the dtype int to make 1 and 0 values.\n",
    "# Store the result in `penguins_encoded` for later use.\n",
    "\n",
    "\n",
    "penguins_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19acd2a5",
   "metadata": {
    "id": "19acd2a5"
   },
   "source": [
    "As you can see, the island column is gone and replaced with three binary columns.  Let's query some random rows to see more than just Torgersen island:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442eafc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1442eafc",
    "outputId": "b45a45de-8e93-480a-dd02-6fec2d225a03"
   },
   "outputs": [],
   "source": [
    "penguins_encoded.sample(n=5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef02ed",
   "metadata": {
    "id": "8aef02ed"
   },
   "source": [
    "#### There's More Than One Way to Do It\n",
    "\n",
    "You can also use the `OneHotEncoder` from Scikit-Learn to encode a single variable.  It is not as simple as the Pandas method shown above when you have categorical and numeric values in a dataframe, but it works great when you need to one-hot encode your output label.  (‚ÑπÔ∏è Some models require that categorical outputs are one-hot encoded.  Scikit-Learn models usually don't require this.)\n",
    "\n",
    "Here's how it would look to encode the `island` column and print five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abc9f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0abc9f0",
    "outputId": "d9ee5a07-29a5-442c-daa1-b767227ed6af"
   },
   "outputs": [],
   "source": [
    "encoded_island = (\n",
    "    OneHotEncoder().fit_transform(penguins[[\"island\"]]).toarray()\n",
    ")  # NOTE: the extra [] is necessary to get the correct shape for the single columns we are selecting.\n",
    "\n",
    "# The following lines are all related to printing five example rows.  The line above did all the hard work.\n",
    "np.random.seed(0)\n",
    "idx = np.random.permutation(np.arange(len(encoded_island)))\n",
    "print(encoded_island[idx[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8277c45",
   "metadata": {
    "id": "d8277c45"
   },
   "source": [
    "There are _several_ also other approaches to encoding categorical values.  \n",
    "\n",
    "You can learn a lot more here: <https://www.kaggle.com/code/arashnic/an-overview-of-categorical-encoding-methods>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51847b37",
   "metadata": {},
   "source": [
    "## Thank You!\n",
    "\n",
    "This notebook in tutorial and completed form is available at:\n",
    "\n",
    "<https://jcausey-astate.github.io/ASRI-2025/>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
